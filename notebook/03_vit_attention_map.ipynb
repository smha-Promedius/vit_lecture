{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGgNYcUBu8B3rMyQhu8OH3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smha-Promedius/vit_lecture/blob/master/notebook/03_vit_attention_map.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-m24d2u5IXij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43f7af54-8821-4569-f98d-53d30be00bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 31 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum* | tail -n 1\n",
        "!sudo fc-cache -fv\n",
        "!rm -rf ~/.cache/matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 & 커맨드 준비"
      ],
      "metadata": {
        "id": "jUcViRGPCOcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요 라이브러리 설치\n",
        "\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1\n",
        "!pip install pytorch-gradcam | tail -n 1\n",
        "w = !apt install tree\n",
        "print(w[-2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZsW0WoUCQr-",
        "outputId": "72494ac1-218e-46d6-cfb4-f779e7bd94dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Successfully installed pytorch-gradcam-0.2.1\n",
            "Use 'apt autoremove' to remove it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 모든 설치가 끝나면 한글 폰트를 바르게 출력하기 위해 **[런타임]** -> **[런타임 다시시작]**을 클릭한 다음, 아래 셀부터 코드를 실행해 주십시오."
      ],
      "metadata": {
        "id": "9MpRCzr8CTHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 라이브러리 임포트\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "\n",
        "# 폰트 관련 용도\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "# 나눔 고딕 폰트의 경로 명시\n",
        "path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
        "font_name = fm.FontProperties(fname=path, size=10).get_name()\n",
        "\n",
        "import cv2, os\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from gradcam.utils import visualize_cam"
      ],
      "metadata": {
        "id": "ZrpR2QeMCTtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 초기설정"
      ],
      "metadata": {
        "id": "g8KviGvXdSrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# warning 표시 끄기\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# 기본 폰트 설정\n",
        "plt.rcParams['font.family'] = font_name\n",
        "\n",
        "# 기본 폰트 사이즈 변경\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# 기본 그래프 사이즈 변경\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# 기본 그리드 표시\n",
        "# 필요에 따라 설정할 때는, plt.grid()\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# 마이너스 기호 정상 출력\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 넘파이 부동소수점 자릿수 표시\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ],
      "metadata": {
        "id": "kC29AxQGdROP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 디바이스 할당\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdnx-HuTCyKh",
        "outputId": "2a59afcd-073b-49f4-94c7-49d13a19dc23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 공통함수 다운로드\n",
        "!git clone https://github.com/smha-Promedius/pythonlibs.git\n",
        "\n",
        "# 공통함수 임포트\n",
        "from pythonlibs.torch_lib1 import *\n",
        "\n",
        "# 공통함수 체크\n",
        "print(README)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wX395Q0zdald",
        "outputId": "1e42592e-458d-4e0b-cdd0-c5aae690796b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pythonlibs'...\n",
            "remote: Enumerating objects: 68, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 68 (delta 5), reused 14 (delta 4), pack-reused 52\u001b[K\n",
            "Unpacking objects: 100% (68/68), done.\n",
            "Common Library for PyTorch\n",
            "Author: M. Akaishi\n",
            "Translator: Seungmin Ha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습 데이터 읽어오기"
      ],
      "metadata": {
        "id": "gfHeBz8Pdc_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 이미지 다운로드\n",
        "w = !wget https://github.com/smha-Promedius/pythonlibs/raw/master/images_vit/colon_vs_lung.zip\n",
        "print(w[-2])\n",
        "\n",
        "# 학습용 이미지 압축풀기\n",
        "w = !unzip colon_vs_lung.zip\n",
        "print(w[-1])\n",
        "# 디렉토리명 설정\n",
        "data_dir = 'colon_vs_lung'\n",
        "\n",
        "# 학습, 테스트 디렉토리명 설정\n",
        "import os\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "valid_dir = os.path.join(data_dir, 'valid')\n",
        "test_dir = os.path.join(data_dir, 'test')\n",
        "\n",
        "# 분류 클래스 설정\n",
        "classes = ['colon', 'lung']\n",
        "\n",
        "# 압축해제 결과 트리 구조 보기\n",
        "!tree colon_vs_lung"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnFDCU7ddb-8",
        "outputId": "d6401427-8cdd-42f9-e4c3-e5859b786e44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-11-19 06:01:56 (387 MB/s) - ‘colon_vs_lung.zip’ saved [56240314/56240314]\n",
            "  inflating: colon_vs_lung/valid/colon/colonn158.jpeg  \n",
            "colon_vs_lung\n",
            "├── test\n",
            "│   ├── colon\n",
            "│   │   ├── colonca10.jpeg\n",
            "│   │   ├── colonca11.jpeg\n",
            "│   │   ├── colonca12.jpeg\n",
            "│   │   ├── colonca13.jpeg\n",
            "│   │   ├── colonca14.jpeg\n",
            "│   │   ├── colonca15.jpeg\n",
            "│   │   ├── colonca16.jpeg\n",
            "│   │   ├── colonca17.jpeg\n",
            "│   │   ├── colonca18.jpeg\n",
            "│   │   ├── colonca19.jpeg\n",
            "│   │   ├── colonca1.jpeg\n",
            "│   │   ├── colonca20.jpeg\n",
            "│   │   ├── colonca21.jpeg\n",
            "│   │   ├── colonca22.jpeg\n",
            "│   │   ├── colonca23.jpeg\n",
            "│   │   ├── colonca24.jpeg\n",
            "│   │   ├── colonca25.jpeg\n",
            "│   │   ├── colonca26.jpeg\n",
            "│   │   ├── colonca27.jpeg\n",
            "│   │   ├── colonca28.jpeg\n",
            "│   │   ├── colonca29.jpeg\n",
            "│   │   ├── colonca2.jpeg\n",
            "│   │   ├── colonca30.jpeg\n",
            "│   │   ├── colonca3.jpeg\n",
            "│   │   ├── colonca4.jpeg\n",
            "│   │   ├── colonca5.jpeg\n",
            "│   │   ├── colonca6.jpeg\n",
            "│   │   ├── colonca7.jpeg\n",
            "│   │   ├── colonca8.jpeg\n",
            "│   │   ├── colonca9.jpeg\n",
            "│   │   ├── colonn10.jpeg\n",
            "│   │   ├── colonn11.jpeg\n",
            "│   │   ├── colonn12.jpeg\n",
            "│   │   ├── colonn13.jpeg\n",
            "│   │   ├── colonn14.jpeg\n",
            "│   │   ├── colonn15.jpeg\n",
            "│   │   ├── colonn16.jpeg\n",
            "│   │   ├── colonn17.jpeg\n",
            "│   │   ├── colonn18.jpeg\n",
            "│   │   ├── colonn19.jpeg\n",
            "│   │   ├── colonn1.jpeg\n",
            "│   │   ├── colonn20.jpeg\n",
            "│   │   ├── colonn21.jpeg\n",
            "│   │   ├── colonn22.jpeg\n",
            "│   │   ├── colonn23.jpeg\n",
            "│   │   ├── colonn24.jpeg\n",
            "│   │   ├── colonn25.jpeg\n",
            "│   │   ├── colonn26.jpeg\n",
            "│   │   ├── colonn27.jpeg\n",
            "│   │   ├── colonn28.jpeg\n",
            "│   │   ├── colonn29.jpeg\n",
            "│   │   ├── colonn2.jpeg\n",
            "│   │   ├── colonn30.jpeg\n",
            "│   │   ├── colonn3.jpeg\n",
            "│   │   ├── colonn4.jpeg\n",
            "│   │   ├── colonn5.jpeg\n",
            "│   │   ├── colonn6.jpeg\n",
            "│   │   ├── colonn7.jpeg\n",
            "│   │   ├── colonn8.jpeg\n",
            "│   │   └── colonn9.jpeg\n",
            "│   └── lung\n",
            "│       ├── lungaca10.jpeg\n",
            "│       ├── lungaca11.jpeg\n",
            "│       ├── lungaca12.jpeg\n",
            "│       ├── lungaca13.jpeg\n",
            "│       ├── lungaca14.jpeg\n",
            "│       ├── lungaca15.jpeg\n",
            "│       ├── lungaca16.jpeg\n",
            "│       ├── lungaca17.jpeg\n",
            "│       ├── lungaca18.jpeg\n",
            "│       ├── lungaca19.jpeg\n",
            "│       ├── lungaca1.jpeg\n",
            "│       ├── lungaca20.jpeg\n",
            "│       ├── lungaca2.jpeg\n",
            "│       ├── lungaca3.jpeg\n",
            "│       ├── lungaca4.jpeg\n",
            "│       ├── lungaca5.jpeg\n",
            "│       ├── lungaca6.jpeg\n",
            "│       ├── lungaca7.jpeg\n",
            "│       ├── lungaca8.jpeg\n",
            "│       ├── lungaca9.jpeg\n",
            "│       ├── lungn10.jpeg\n",
            "│       ├── lungn11.jpeg\n",
            "│       ├── lungn12.jpeg\n",
            "│       ├── lungn13.jpeg\n",
            "│       ├── lungn14.jpeg\n",
            "│       ├── lungn15.jpeg\n",
            "│       ├── lungn16.jpeg\n",
            "│       ├── lungn17.jpeg\n",
            "│       ├── lungn18.jpeg\n",
            "│       ├── lungn19.jpeg\n",
            "│       ├── lungn1.jpeg\n",
            "│       ├── lungn20.jpeg\n",
            "│       ├── lungn2.jpeg\n",
            "│       ├── lungn3.jpeg\n",
            "│       ├── lungn4.jpeg\n",
            "│       ├── lungn5.jpeg\n",
            "│       ├── lungn6.jpeg\n",
            "│       ├── lungn7.jpeg\n",
            "│       ├── lungn8.jpeg\n",
            "│       ├── lungn9.jpeg\n",
            "│       ├── lungscc10.jpeg\n",
            "│       ├── lungscc11.jpeg\n",
            "│       ├── lungscc12.jpeg\n",
            "│       ├── lungscc13.jpeg\n",
            "│       ├── lungscc14.jpeg\n",
            "│       ├── lungscc15.jpeg\n",
            "│       ├── lungscc16.jpeg\n",
            "│       ├── lungscc17.jpeg\n",
            "│       ├── lungscc18.jpeg\n",
            "│       ├── lungscc19.jpeg\n",
            "│       ├── lungscc1.jpeg\n",
            "│       ├── lungscc20.jpeg\n",
            "│       ├── lungscc2.jpeg\n",
            "│       ├── lungscc3.jpeg\n",
            "│       ├── lungscc4.jpeg\n",
            "│       ├── lungscc5.jpeg\n",
            "│       ├── lungscc6.jpeg\n",
            "│       ├── lungscc7.jpeg\n",
            "│       ├── lungscc8.jpeg\n",
            "│       └── lungscc9.jpeg\n",
            "├── train\n",
            "│   ├── colon\n",
            "│   │   ├── colonca100.jpeg\n",
            "│   │   ├── colonca101.jpeg\n",
            "│   │   ├── colonca102.jpeg\n",
            "│   │   ├── colonca103.jpeg\n",
            "│   │   ├── colonca104.jpeg\n",
            "│   │   ├── colonca105.jpeg\n",
            "│   │   ├── colonca106.jpeg\n",
            "│   │   ├── colonca107.jpeg\n",
            "│   │   ├── colonca108.jpeg\n",
            "│   │   ├── colonca109.jpeg\n",
            "│   │   ├── colonca110.jpeg\n",
            "│   │   ├── colonca111.jpeg\n",
            "│   │   ├── colonca112.jpeg\n",
            "│   │   ├── colonca113.jpeg\n",
            "│   │   ├── colonca114.jpeg\n",
            "│   │   ├── colonca115.jpeg\n",
            "│   │   ├── colonca116.jpeg\n",
            "│   │   ├── colonca117.jpeg\n",
            "│   │   ├── colonca118.jpeg\n",
            "│   │   ├── colonca119.jpeg\n",
            "│   │   ├── colonca120.jpeg\n",
            "│   │   ├── colonca121.jpeg\n",
            "│   │   ├── colonca122.jpeg\n",
            "│   │   ├── colonca123.jpeg\n",
            "│   │   ├── colonca124.jpeg\n",
            "│   │   ├── colonca125.jpeg\n",
            "│   │   ├── colonca126.jpeg\n",
            "│   │   ├── colonca127.jpeg\n",
            "│   │   ├── colonca128.jpeg\n",
            "│   │   ├── colonca129.jpeg\n",
            "│   │   ├── colonca130.jpeg\n",
            "│   │   ├── colonca131.jpeg\n",
            "│   │   ├── colonca132.jpeg\n",
            "│   │   ├── colonca133.jpeg\n",
            "│   │   ├── colonca134.jpeg\n",
            "│   │   ├── colonca135.jpeg\n",
            "│   │   ├── colonca136.jpeg\n",
            "│   │   ├── colonca137.jpeg\n",
            "│   │   ├── colonca138.jpeg\n",
            "│   │   ├── colonca139.jpeg\n",
            "│   │   ├── colonca140.jpeg\n",
            "│   │   ├── colonca141.jpeg\n",
            "│   │   ├── colonca142.jpeg\n",
            "│   │   ├── colonca143.jpeg\n",
            "│   │   ├── colonca144.jpeg\n",
            "│   │   ├── colonca145.jpeg\n",
            "│   │   ├── colonca146.jpeg\n",
            "│   │   ├── colonca147.jpeg\n",
            "│   │   ├── colonca148.jpeg\n",
            "│   │   ├── colonca149.jpeg\n",
            "│   │   ├── colonca150.jpeg\n",
            "│   │   ├── colonca31.jpeg\n",
            "│   │   ├── colonca32.jpeg\n",
            "│   │   ├── colonca33.jpeg\n",
            "│   │   ├── colonca34.jpeg\n",
            "│   │   ├── colonca35.jpeg\n",
            "│   │   ├── colonca36.jpeg\n",
            "│   │   ├── colonca37.jpeg\n",
            "│   │   ├── colonca38.jpeg\n",
            "│   │   ├── colonca39.jpeg\n",
            "│   │   ├── colonca40.jpeg\n",
            "│   │   ├── colonca41.jpeg\n",
            "│   │   ├── colonca42.jpeg\n",
            "│   │   ├── colonca43.jpeg\n",
            "│   │   ├── colonca44.jpeg\n",
            "│   │   ├── colonca45.jpeg\n",
            "│   │   ├── colonca46.jpeg\n",
            "│   │   ├── colonca47.jpeg\n",
            "│   │   ├── colonca48.jpeg\n",
            "│   │   ├── colonca49.jpeg\n",
            "│   │   ├── colonca50.jpeg\n",
            "│   │   ├── colonca51.jpeg\n",
            "│   │   ├── colonca52.jpeg\n",
            "│   │   ├── colonca53.jpeg\n",
            "│   │   ├── colonca54.jpeg\n",
            "│   │   ├── colonca55.jpeg\n",
            "│   │   ├── colonca56.jpeg\n",
            "│   │   ├── colonca57.jpeg\n",
            "│   │   ├── colonca58.jpeg\n",
            "│   │   ├── colonca59.jpeg\n",
            "│   │   ├── colonca60.jpeg\n",
            "│   │   ├── colonca61.jpeg\n",
            "│   │   ├── colonca62.jpeg\n",
            "│   │   ├── colonca63.jpeg\n",
            "│   │   ├── colonca64.jpeg\n",
            "│   │   ├── colonca65.jpeg\n",
            "│   │   ├── colonca66.jpeg\n",
            "│   │   ├── colonca67.jpeg\n",
            "│   │   ├── colonca68.jpeg\n",
            "│   │   ├── colonca69.jpeg\n",
            "│   │   ├── colonca70.jpeg\n",
            "│   │   ├── colonca71.jpeg\n",
            "│   │   ├── colonca72.jpeg\n",
            "│   │   ├── colonca73.jpeg\n",
            "│   │   ├── colonca74.jpeg\n",
            "│   │   ├── colonca75.jpeg\n",
            "│   │   ├── colonca76.jpeg\n",
            "│   │   ├── colonca77.jpeg\n",
            "│   │   ├── colonca78.jpeg\n",
            "│   │   ├── colonca79.jpeg\n",
            "│   │   ├── colonca80.jpeg\n",
            "│   │   ├── colonca81.jpeg\n",
            "│   │   ├── colonca82.jpeg\n",
            "│   │   ├── colonca83.jpeg\n",
            "│   │   ├── colonca84.jpeg\n",
            "│   │   ├── colonca85.jpeg\n",
            "│   │   ├── colonca86.jpeg\n",
            "│   │   ├── colonca87.jpeg\n",
            "│   │   ├── colonca88.jpeg\n",
            "│   │   ├── colonca89.jpeg\n",
            "│   │   ├── colonca90.jpeg\n",
            "│   │   ├── colonca91.jpeg\n",
            "│   │   ├── colonca92.jpeg\n",
            "│   │   ├── colonca93.jpeg\n",
            "│   │   ├── colonca94.jpeg\n",
            "│   │   ├── colonca95.jpeg\n",
            "│   │   ├── colonca96.jpeg\n",
            "│   │   ├── colonca97.jpeg\n",
            "│   │   ├── colonca98.jpeg\n",
            "│   │   ├── colonca99.jpeg\n",
            "│   │   ├── colonn100.jpeg\n",
            "│   │   ├── colonn101.jpeg\n",
            "│   │   ├── colonn102.jpeg\n",
            "│   │   ├── colonn103.jpeg\n",
            "│   │   ├── colonn104.jpeg\n",
            "│   │   ├── colonn105.jpeg\n",
            "│   │   ├── colonn106.jpeg\n",
            "│   │   ├── colonn107.jpeg\n",
            "│   │   ├── colonn108.jpeg\n",
            "│   │   ├── colonn109.jpeg\n",
            "│   │   ├── colonn110.jpeg\n",
            "│   │   ├── colonn111.jpeg\n",
            "│   │   ├── colonn112.jpeg\n",
            "│   │   ├── colonn113.jpeg\n",
            "│   │   ├── colonn114.jpeg\n",
            "│   │   ├── colonn115.jpeg\n",
            "│   │   ├── colonn116.jpeg\n",
            "│   │   ├── colonn117.jpeg\n",
            "│   │   ├── colonn118.jpeg\n",
            "│   │   ├── colonn119.jpeg\n",
            "│   │   ├── colonn120.jpeg\n",
            "│   │   ├── colonn121.jpeg\n",
            "│   │   ├── colonn122.jpeg\n",
            "│   │   ├── colonn123.jpeg\n",
            "│   │   ├── colonn124.jpeg\n",
            "│   │   ├── colonn125.jpeg\n",
            "│   │   ├── colonn126.jpeg\n",
            "│   │   ├── colonn127.jpeg\n",
            "│   │   ├── colonn128.jpeg\n",
            "│   │   ├── colonn129.jpeg\n",
            "│   │   ├── colonn130.jpeg\n",
            "│   │   ├── colonn131.jpeg\n",
            "│   │   ├── colonn132.jpeg\n",
            "│   │   ├── colonn133.jpeg\n",
            "│   │   ├── colonn134.jpeg\n",
            "│   │   ├── colonn135.jpeg\n",
            "│   │   ├── colonn136.jpeg\n",
            "│   │   ├── colonn137.jpeg\n",
            "│   │   ├── colonn138.jpeg\n",
            "│   │   ├── colonn139.jpeg\n",
            "│   │   ├── colonn140.jpeg\n",
            "│   │   ├── colonn141.jpeg\n",
            "│   │   ├── colonn142.jpeg\n",
            "│   │   ├── colonn143.jpeg\n",
            "│   │   ├── colonn144.jpeg\n",
            "│   │   ├── colonn145.jpeg\n",
            "│   │   ├── colonn146.jpeg\n",
            "│   │   ├── colonn147.jpeg\n",
            "│   │   ├── colonn148.jpeg\n",
            "│   │   ├── colonn149.jpeg\n",
            "│   │   ├── colonn150.jpeg\n",
            "│   │   ├── colonn31.jpeg\n",
            "│   │   ├── colonn32.jpeg\n",
            "│   │   ├── colonn33.jpeg\n",
            "│   │   ├── colonn34.jpeg\n",
            "│   │   ├── colonn35.jpeg\n",
            "│   │   ├── colonn36.jpeg\n",
            "│   │   ├── colonn37.jpeg\n",
            "│   │   ├── colonn38.jpeg\n",
            "│   │   ├── colonn39.jpeg\n",
            "│   │   ├── colonn40.jpeg\n",
            "│   │   ├── colonn41.jpeg\n",
            "│   │   ├── colonn42.jpeg\n",
            "│   │   ├── colonn43.jpeg\n",
            "│   │   ├── colonn44.jpeg\n",
            "│   │   ├── colonn45.jpeg\n",
            "│   │   ├── colonn46.jpeg\n",
            "│   │   ├── colonn47.jpeg\n",
            "│   │   ├── colonn48.jpeg\n",
            "│   │   ├── colonn49.jpeg\n",
            "│   │   ├── colonn50.jpeg\n",
            "│   │   ├── colonn51.jpeg\n",
            "│   │   ├── colonn52.jpeg\n",
            "│   │   ├── colonn53.jpeg\n",
            "│   │   ├── colonn54.jpeg\n",
            "│   │   ├── colonn55.jpeg\n",
            "│   │   ├── colonn56.jpeg\n",
            "│   │   ├── colonn57.jpeg\n",
            "│   │   ├── colonn58.jpeg\n",
            "│   │   ├── colonn59.jpeg\n",
            "│   │   ├── colonn60.jpeg\n",
            "│   │   ├── colonn61.jpeg\n",
            "│   │   ├── colonn62.jpeg\n",
            "│   │   ├── colonn63.jpeg\n",
            "│   │   ├── colonn64.jpeg\n",
            "│   │   ├── colonn65.jpeg\n",
            "│   │   ├── colonn66.jpeg\n",
            "│   │   ├── colonn67.jpeg\n",
            "│   │   ├── colonn68.jpeg\n",
            "│   │   ├── colonn69.jpeg\n",
            "│   │   ├── colonn70.jpeg\n",
            "│   │   ├── colonn71.jpeg\n",
            "│   │   ├── colonn72.jpeg\n",
            "│   │   ├── colonn73.jpeg\n",
            "│   │   ├── colonn74.jpeg\n",
            "│   │   ├── colonn75.jpeg\n",
            "│   │   ├── colonn76.jpeg\n",
            "│   │   ├── colonn77.jpeg\n",
            "│   │   ├── colonn78.jpeg\n",
            "│   │   ├── colonn79.jpeg\n",
            "│   │   ├── colonn80.jpeg\n",
            "│   │   ├── colonn81.jpeg\n",
            "│   │   ├── colonn82.jpeg\n",
            "│   │   ├── colonn83.jpeg\n",
            "│   │   ├── colonn84.jpeg\n",
            "│   │   ├── colonn85.jpeg\n",
            "│   │   ├── colonn86.jpeg\n",
            "│   │   ├── colonn87.jpeg\n",
            "│   │   ├── colonn88.jpeg\n",
            "│   │   ├── colonn89.jpeg\n",
            "│   │   ├── colonn90.jpeg\n",
            "│   │   ├── colonn91.jpeg\n",
            "│   │   ├── colonn92.jpeg\n",
            "│   │   ├── colonn93.jpeg\n",
            "│   │   ├── colonn94.jpeg\n",
            "│   │   ├── colonn95.jpeg\n",
            "│   │   ├── colonn96.jpeg\n",
            "│   │   ├── colonn97.jpeg\n",
            "│   │   ├── colonn98.jpeg\n",
            "│   │   └── colonn99.jpeg\n",
            "│   └── lung\n",
            "│       ├── lungaca100.jpeg\n",
            "│       ├── lungaca21.jpeg\n",
            "│       ├── lungaca22.jpeg\n",
            "│       ├── lungaca23.jpeg\n",
            "│       ├── lungaca24.jpeg\n",
            "│       ├── lungaca25.jpeg\n",
            "│       ├── lungaca26.jpeg\n",
            "│       ├── lungaca27.jpeg\n",
            "│       ├── lungaca28.jpeg\n",
            "│       ├── lungaca29.jpeg\n",
            "│       ├── lungaca30.jpeg\n",
            "│       ├── lungaca31.jpeg\n",
            "│       ├── lungaca32.jpeg\n",
            "│       ├── lungaca33.jpeg\n",
            "│       ├── lungaca34.jpeg\n",
            "│       ├── lungaca35.jpeg\n",
            "│       ├── lungaca36.jpeg\n",
            "│       ├── lungaca37.jpeg\n",
            "│       ├── lungaca38.jpeg\n",
            "│       ├── lungaca39.jpeg\n",
            "│       ├── lungaca40.jpeg\n",
            "│       ├── lungaca41.jpeg\n",
            "│       ├── lungaca42.jpeg\n",
            "│       ├── lungaca43.jpeg\n",
            "│       ├── lungaca44.jpeg\n",
            "│       ├── lungaca45.jpeg\n",
            "│       ├── lungaca46.jpeg\n",
            "│       ├── lungaca47.jpeg\n",
            "│       ├── lungaca48.jpeg\n",
            "│       ├── lungaca49.jpeg\n",
            "│       ├── lungaca50.jpeg\n",
            "│       ├── lungaca51.jpeg\n",
            "│       ├── lungaca52.jpeg\n",
            "│       ├── lungaca53.jpeg\n",
            "│       ├── lungaca54.jpeg\n",
            "│       ├── lungaca55.jpeg\n",
            "│       ├── lungaca56.jpeg\n",
            "│       ├── lungaca57.jpeg\n",
            "│       ├── lungaca58.jpeg\n",
            "│       ├── lungaca59.jpeg\n",
            "│       ├── lungaca60.jpeg\n",
            "│       ├── lungaca61.jpeg\n",
            "│       ├── lungaca62.jpeg\n",
            "│       ├── lungaca63.jpeg\n",
            "│       ├── lungaca64.jpeg\n",
            "│       ├── lungaca65.jpeg\n",
            "│       ├── lungaca66.jpeg\n",
            "│       ├── lungaca67.jpeg\n",
            "│       ├── lungaca68.jpeg\n",
            "│       ├── lungaca69.jpeg\n",
            "│       ├── lungaca70.jpeg\n",
            "│       ├── lungaca71.jpeg\n",
            "│       ├── lungaca72.jpeg\n",
            "│       ├── lungaca73.jpeg\n",
            "│       ├── lungaca74.jpeg\n",
            "│       ├── lungaca75.jpeg\n",
            "│       ├── lungaca76.jpeg\n",
            "│       ├── lungaca77.jpeg\n",
            "│       ├── lungaca78.jpeg\n",
            "│       ├── lungaca79.jpeg\n",
            "│       ├── lungaca80.jpeg\n",
            "│       ├── lungaca81.jpeg\n",
            "│       ├── lungaca82.jpeg\n",
            "│       ├── lungaca83.jpeg\n",
            "│       ├── lungaca84.jpeg\n",
            "│       ├── lungaca85.jpeg\n",
            "│       ├── lungaca86.jpeg\n",
            "│       ├── lungaca87.jpeg\n",
            "│       ├── lungaca88.jpeg\n",
            "│       ├── lungaca89.jpeg\n",
            "│       ├── lungaca90.jpeg\n",
            "│       ├── lungaca91.jpeg\n",
            "│       ├── lungaca92.jpeg\n",
            "│       ├── lungaca93.jpeg\n",
            "│       ├── lungaca94.jpeg\n",
            "│       ├── lungaca95.jpeg\n",
            "│       ├── lungaca96.jpeg\n",
            "│       ├── lungaca97.jpeg\n",
            "│       ├── lungaca98.jpeg\n",
            "│       ├── lungaca99.jpeg\n",
            "│       ├── lungn100.jpeg\n",
            "│       ├── lungn21.jpeg\n",
            "│       ├── lungn22.jpeg\n",
            "│       ├── lungn23.jpeg\n",
            "│       ├── lungn24.jpeg\n",
            "│       ├── lungn25.jpeg\n",
            "│       ├── lungn26.jpeg\n",
            "│       ├── lungn27.jpeg\n",
            "│       ├── lungn28.jpeg\n",
            "│       ├── lungn29.jpeg\n",
            "│       ├── lungn30.jpeg\n",
            "│       ├── lungn31.jpeg\n",
            "│       ├── lungn32.jpeg\n",
            "│       ├── lungn33.jpeg\n",
            "│       ├── lungn34.jpeg\n",
            "│       ├── lungn35.jpeg\n",
            "│       ├── lungn36.jpeg\n",
            "│       ├── lungn37.jpeg\n",
            "│       ├── lungn38.jpeg\n",
            "│       ├── lungn39.jpeg\n",
            "│       ├── lungn40.jpeg\n",
            "│       ├── lungn41.jpeg\n",
            "│       ├── lungn42.jpeg\n",
            "│       ├── lungn43.jpeg\n",
            "│       ├── lungn44.jpeg\n",
            "│       ├── lungn45.jpeg\n",
            "│       ├── lungn46.jpeg\n",
            "│       ├── lungn47.jpeg\n",
            "│       ├── lungn48.jpeg\n",
            "│       ├── lungn49.jpeg\n",
            "│       ├── lungn50.jpeg\n",
            "│       ├── lungn51.jpeg\n",
            "│       ├── lungn52.jpeg\n",
            "│       ├── lungn53.jpeg\n",
            "│       ├── lungn54.jpeg\n",
            "│       ├── lungn55.jpeg\n",
            "│       ├── lungn56.jpeg\n",
            "│       ├── lungn57.jpeg\n",
            "│       ├── lungn58.jpeg\n",
            "│       ├── lungn59.jpeg\n",
            "│       ├── lungn60.jpeg\n",
            "│       ├── lungn61.jpeg\n",
            "│       ├── lungn62.jpeg\n",
            "│       ├── lungn63.jpeg\n",
            "│       ├── lungn64.jpeg\n",
            "│       ├── lungn65.jpeg\n",
            "│       ├── lungn66.jpeg\n",
            "│       ├── lungn67.jpeg\n",
            "│       ├── lungn68.jpeg\n",
            "│       ├── lungn69.jpeg\n",
            "│       ├── lungn70.jpeg\n",
            "│       ├── lungn71.jpeg\n",
            "│       ├── lungn72.jpeg\n",
            "│       ├── lungn73.jpeg\n",
            "│       ├── lungn74.jpeg\n",
            "│       ├── lungn75.jpeg\n",
            "│       ├── lungn76.jpeg\n",
            "│       ├── lungn77.jpeg\n",
            "│       ├── lungn78.jpeg\n",
            "│       ├── lungn79.jpeg\n",
            "│       ├── lungn80.jpeg\n",
            "│       ├── lungn81.jpeg\n",
            "│       ├── lungn82.jpeg\n",
            "│       ├── lungn83.jpeg\n",
            "│       ├── lungn84.jpeg\n",
            "│       ├── lungn85.jpeg\n",
            "│       ├── lungn86.jpeg\n",
            "│       ├── lungn87.jpeg\n",
            "│       ├── lungn88.jpeg\n",
            "│       ├── lungn89.jpeg\n",
            "│       ├── lungn90.jpeg\n",
            "│       ├── lungn91.jpeg\n",
            "│       ├── lungn92.jpeg\n",
            "│       ├── lungn93.jpeg\n",
            "│       ├── lungn94.jpeg\n",
            "│       ├── lungn95.jpeg\n",
            "│       ├── lungn96.jpeg\n",
            "│       ├── lungn97.jpeg\n",
            "│       ├── lungn98.jpeg\n",
            "│       ├── lungn99.jpeg\n",
            "│       ├── lungscc100.jpeg\n",
            "│       ├── lungscc21.jpeg\n",
            "│       ├── lungscc22.jpeg\n",
            "│       ├── lungscc23.jpeg\n",
            "│       ├── lungscc24.jpeg\n",
            "│       ├── lungscc25.jpeg\n",
            "│       ├── lungscc26.jpeg\n",
            "│       ├── lungscc27.jpeg\n",
            "│       ├── lungscc28.jpeg\n",
            "│       ├── lungscc29.jpeg\n",
            "│       ├── lungscc30.jpeg\n",
            "│       ├── lungscc31.jpeg\n",
            "│       ├── lungscc32.jpeg\n",
            "│       ├── lungscc33.jpeg\n",
            "│       ├── lungscc34.jpeg\n",
            "│       ├── lungscc35.jpeg\n",
            "│       ├── lungscc36.jpeg\n",
            "│       ├── lungscc37.jpeg\n",
            "│       ├── lungscc38.jpeg\n",
            "│       ├── lungscc39.jpeg\n",
            "│       ├── lungscc40.jpeg\n",
            "│       ├── lungscc41.jpeg\n",
            "│       ├── lungscc42.jpeg\n",
            "│       ├── lungscc43.jpeg\n",
            "│       ├── lungscc44.jpeg\n",
            "│       ├── lungscc45.jpeg\n",
            "│       ├── lungscc46.jpeg\n",
            "│       ├── lungscc47.jpeg\n",
            "│       ├── lungscc48.jpeg\n",
            "│       ├── lungscc49.jpeg\n",
            "│       ├── lungscc50.jpeg\n",
            "│       ├── lungscc51.jpeg\n",
            "│       ├── lungscc52.jpeg\n",
            "│       ├── lungscc53.jpeg\n",
            "│       ├── lungscc54.jpeg\n",
            "│       ├── lungscc55.jpeg\n",
            "│       ├── lungscc56.jpeg\n",
            "│       ├── lungscc57.jpeg\n",
            "│       ├── lungscc58.jpeg\n",
            "│       ├── lungscc59.jpeg\n",
            "│       ├── lungscc60.jpeg\n",
            "│       ├── lungscc61.jpeg\n",
            "│       ├── lungscc62.jpeg\n",
            "│       ├── lungscc63.jpeg\n",
            "│       ├── lungscc64.jpeg\n",
            "│       ├── lungscc65.jpeg\n",
            "│       ├── lungscc66.jpeg\n",
            "│       ├── lungscc67.jpeg\n",
            "│       ├── lungscc68.jpeg\n",
            "│       ├── lungscc69.jpeg\n",
            "│       ├── lungscc70.jpeg\n",
            "│       ├── lungscc71.jpeg\n",
            "│       ├── lungscc72.jpeg\n",
            "│       ├── lungscc73.jpeg\n",
            "│       ├── lungscc74.jpeg\n",
            "│       ├── lungscc75.jpeg\n",
            "│       ├── lungscc76.jpeg\n",
            "│       ├── lungscc77.jpeg\n",
            "│       ├── lungscc78.jpeg\n",
            "│       ├── lungscc79.jpeg\n",
            "│       ├── lungscc80.jpeg\n",
            "│       ├── lungscc81.jpeg\n",
            "│       ├── lungscc82.jpeg\n",
            "│       ├── lungscc83.jpeg\n",
            "│       ├── lungscc84.jpeg\n",
            "│       ├── lungscc85.jpeg\n",
            "│       ├── lungscc86.jpeg\n",
            "│       ├── lungscc87.jpeg\n",
            "│       ├── lungscc88.jpeg\n",
            "│       ├── lungscc89.jpeg\n",
            "│       ├── lungscc90.jpeg\n",
            "│       ├── lungscc91.jpeg\n",
            "│       ├── lungscc92.jpeg\n",
            "│       ├── lungscc93.jpeg\n",
            "│       ├── lungscc94.jpeg\n",
            "│       ├── lungscc95.jpeg\n",
            "│       ├── lungscc96.jpeg\n",
            "│       ├── lungscc97.jpeg\n",
            "│       ├── lungscc98.jpeg\n",
            "│       └── lungscc99.jpeg\n",
            "└── valid\n",
            "    ├── colon\n",
            "    │   ├── colonca151.jpeg\n",
            "    │   ├── colonca152.jpeg\n",
            "    │   ├── colonca153.jpeg\n",
            "    │   ├── colonca154.jpeg\n",
            "    │   ├── colonca155.jpeg\n",
            "    │   ├── colonca156.jpeg\n",
            "    │   ├── colonca157.jpeg\n",
            "    │   ├── colonca158.jpeg\n",
            "    │   ├── colonca159.jpeg\n",
            "    │   ├── colonca160.jpeg\n",
            "    │   ├── colonca161.jpeg\n",
            "    │   ├── colonca162.jpeg\n",
            "    │   ├── colonca163.jpeg\n",
            "    │   ├── colonca164.jpeg\n",
            "    │   ├── colonca165.jpeg\n",
            "    │   ├── colonca166.jpeg\n",
            "    │   ├── colonca167.jpeg\n",
            "    │   ├── colonca168.jpeg\n",
            "    │   ├── colonca169.jpeg\n",
            "    │   ├── colonca170.jpeg\n",
            "    │   ├── colonca171.jpeg\n",
            "    │   ├── colonca172.jpeg\n",
            "    │   ├── colonca173.jpeg\n",
            "    │   ├── colonca174.jpeg\n",
            "    │   ├── colonca175.jpeg\n",
            "    │   ├── colonca176.jpeg\n",
            "    │   ├── colonca177.jpeg\n",
            "    │   ├── colonca178.jpeg\n",
            "    │   ├── colonca179.jpeg\n",
            "    │   ├── colonca180.jpeg\n",
            "    │   ├── colonn151.jpeg\n",
            "    │   ├── colonn152.jpeg\n",
            "    │   ├── colonn153.jpeg\n",
            "    │   ├── colonn154.jpeg\n",
            "    │   ├── colonn155.jpeg\n",
            "    │   ├── colonn156.jpeg\n",
            "    │   ├── colonn157.jpeg\n",
            "    │   ├── colonn158.jpeg\n",
            "    │   ├── colonn159.jpeg\n",
            "    │   ├── colonn160.jpeg\n",
            "    │   ├── colonn161.jpeg\n",
            "    │   ├── colonn162.jpeg\n",
            "    │   ├── colonn163.jpeg\n",
            "    │   ├── colonn164.jpeg\n",
            "    │   ├── colonn165.jpeg\n",
            "    │   ├── colonn166.jpeg\n",
            "    │   ├── colonn167.jpeg\n",
            "    │   ├── colonn168.jpeg\n",
            "    │   ├── colonn169.jpeg\n",
            "    │   ├── colonn170.jpeg\n",
            "    │   ├── colonn171.jpeg\n",
            "    │   ├── colonn172.jpeg\n",
            "    │   ├── colonn173.jpeg\n",
            "    │   ├── colonn174.jpeg\n",
            "    │   ├── colonn175.jpeg\n",
            "    │   ├── colonn176.jpeg\n",
            "    │   ├── colonn177.jpeg\n",
            "    │   ├── colonn178.jpeg\n",
            "    │   ├── colonn179.jpeg\n",
            "    │   └── colonn180.jpeg\n",
            "    └── lung\n",
            "        ├── lungaca101.jpeg\n",
            "        ├── lungaca102.jpeg\n",
            "        ├── lungaca103.jpeg\n",
            "        ├── lungaca104.jpeg\n",
            "        ├── lungaca105.jpeg\n",
            "        ├── lungaca106.jpeg\n",
            "        ├── lungaca107.jpeg\n",
            "        ├── lungaca108.jpeg\n",
            "        ├── lungaca109.jpeg\n",
            "        ├── lungaca110.jpeg\n",
            "        ├── lungaca111.jpeg\n",
            "        ├── lungaca112.jpeg\n",
            "        ├── lungaca113.jpeg\n",
            "        ├── lungaca114.jpeg\n",
            "        ├── lungaca115.jpeg\n",
            "        ├── lungaca116.jpeg\n",
            "        ├── lungaca117.jpeg\n",
            "        ├── lungaca118.jpeg\n",
            "        ├── lungaca119.jpeg\n",
            "        ├── lungaca120.jpeg\n",
            "        ├── lungn101.jpeg\n",
            "        ├── lungn102.jpeg\n",
            "        ├── lungn103.jpeg\n",
            "        ├── lungn104.jpeg\n",
            "        ├── lungn105.jpeg\n",
            "        ├── lungn106.jpeg\n",
            "        ├── lungn107.jpeg\n",
            "        ├── lungn108.jpeg\n",
            "        ├── lungn109.jpeg\n",
            "        ├── lungn110.jpeg\n",
            "        ├── lungn111.jpeg\n",
            "        ├── lungn112.jpeg\n",
            "        ├── lungn113.jpeg\n",
            "        ├── lungn114.jpeg\n",
            "        ├── lungn115.jpeg\n",
            "        ├── lungn116.jpeg\n",
            "        ├── lungn117.jpeg\n",
            "        ├── lungn118.jpeg\n",
            "        ├── lungn119.jpeg\n",
            "        ├── lungn120.jpeg\n",
            "        ├── lungscc101.jpeg\n",
            "        ├── lungscc102.jpeg\n",
            "        ├── lungscc103.jpeg\n",
            "        ├── lungscc104.jpeg\n",
            "        ├── lungscc105.jpeg\n",
            "        ├── lungscc106.jpeg\n",
            "        ├── lungscc107.jpeg\n",
            "        ├── lungscc108.jpeg\n",
            "        ├── lungscc109.jpeg\n",
            "        ├── lungscc110.jpeg\n",
            "        ├── lungscc111.jpeg\n",
            "        ├── lungscc112.jpeg\n",
            "        ├── lungscc113.jpeg\n",
            "        ├── lungscc114.jpeg\n",
            "        ├── lungscc115.jpeg\n",
            "        ├── lungscc116.jpeg\n",
            "        ├── lungscc117.jpeg\n",
            "        ├── lungscc118.jpeg\n",
            "        ├── lungscc119.jpeg\n",
            "        └── lungscc120.jpeg\n",
            "\n",
            "9 directories, 720 files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attention weight를 얻기 위한 메서드"
      ],
      "metadata": {
        "id": "ZHo3elLLfoU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention Weight를 가져오기 위한 함수 \n",
        "def extract(pre_model, target, inputs):\n",
        "    feature = None\n",
        "    def forward_hook(module, inputs, outputs):\n",
        "        # 순전파 출력을 features 글로벌 변수에 기록 \n",
        "        global blocks\n",
        "        blocks = outputs.detach()\n",
        "    # 콜백 함수 등록\n",
        "    handle = target.register_forward_hook(forward_hook) # 추론\n",
        "    pre_model.eval()\n",
        "    pre_model(inputs)\n",
        "    # 콜백 함수 해제\n",
        "    handle.remove()\n",
        "    return blocks"
      ],
      "metadata": {
        "id": "QFTzoagIfnaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습이 끝난 모델 불러오기"
      ],
      "metadata": {
        "id": "0k0UDyAOf9w3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VitInputLayer(nn.Module): \n",
        "    def __init__(self, in_channels:int=3, emb_dim:int=384, num_patch_row:int=4, image_size:int=224):\n",
        "        \"\"\" \n",
        "        인수 : \n",
        "            in_channels: 입력 이미지 채널 수\n",
        "            emb_dim: 임베딩 벡터 길이\n",
        "            num_patch_row: 높이 방향 패치 수. 예시는 2x2이므로 2를 기본값으로 함 \n",
        "            image_size: 입력 이미지 한 변의 길이. 입력 이미지의 높이와 폭은 동일하다고 가정\n",
        "        \"\"\"\n",
        "        super(VitInputLayer, self).__init__() \n",
        "        self.in_channels=in_channels \n",
        "        self.emb_dim = emb_dim \n",
        "        self.num_patch_row = num_patch_row \n",
        "        self.image_size = image_size\n",
        "        \n",
        "        # 패치 수\n",
        "        ## 예: 입력 이미지를 2x2 패치로 나눴을 경우, num_patch는 4\n",
        "        self.num_patch = self.num_patch_row**2\n",
        "\n",
        "        # 패치 크기\n",
        "        ## 예: 입력 이미지 한 변의 길이가 32인 경우, patch_size는 16 \n",
        "        self.patch_size = int(self.image_size // self.num_patch_row)\n",
        "\n",
        "        # 입력 이미지를 패치로 분할 & 패치 임베딩을 한번에 수행 \n",
        "        self.patch_emb_layer = nn.Conv2d(\n",
        "            in_channels=self.in_channels, \n",
        "            out_channels=self.emb_dim, \n",
        "            kernel_size=self.patch_size, \n",
        "            stride=self.patch_size\n",
        "        )\n",
        "\n",
        "        # CLS 토큰 \n",
        "        self.cls_token = nn.Parameter(\n",
        "            torch.randn(1, 1, emb_dim) \n",
        "        )\n",
        "\n",
        "        # 위치 임베딩\n",
        "        ## CLS 토큰이 앞에 결속되어 있기 때문에\n",
        "        ## 길이 emb_dim의 위치 임베딩 벡터를 (패치 수 +1)개 준비 \n",
        "        self.pos_emb = nn.Parameter(\n",
        "            torch.randn(1, self.num_patch+1, emb_dim) \n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" \n",
        "        인수:\n",
        "            x: 입력 이미지. 사이즈는 (B, C, H, W)\n",
        "                B: 배치 사이즈, C: 채널 수, H: 높이, W: 폭\n",
        "        반환값:\n",
        "            z_0: ViT로의 입력값. 사이즈는 (B, N, D)\n",
        "                B: 배치 사이즈, N: 토큰 수, D: 임베딩 벡터 길이\n",
        "        \"\"\"\n",
        "        # 패치 임베딩 & flatten\n",
        "        ## 패치 임베딩 (B, C, H, W) -> (B, D, H/P, W/P) \n",
        "        ## 여기서 P는 패치 한 변의 길이\n",
        "        z_0 = self.patch_emb_layer(x)\n",
        "\n",
        "        ## 패치 flatten (B, D, H/P, W/P) -> (B, D, Np) \n",
        "        ## 여기서 Np는 패치 수(=H*W/Pˆ2)\n",
        "        z_0 = z_0.flatten(2)\n",
        "\n",
        "        ## axis 교환 (B, D, Np) -> (B, Np, D) \n",
        "        z_0 = z_0.transpose(1, 2)\n",
        "\n",
        "        # 패치 임베딩 앞쪽에 CLS 토큰을 결합 \n",
        "        ## (B, Np, D) -> (B, N, D)\n",
        "        ## N = (Np + 1)\n",
        "        ## cls_token의 사이즈는 (1,1,D) 이므로\n",
        "        ## repeat 메서드가 (B,1,D)로 변환하고 나서 패치 임베딩과 결합 \n",
        "        z_0 = torch.cat(\n",
        "            [self.cls_token.repeat(repeats=(x.size(0),1,1)), z_0], dim=1)\n",
        "\n",
        "        # 위치 임베딩을 더함 \n",
        "        ## (B, N, D) -> (B, N, D) \n",
        "        z_0 = z_0 + self.pos_emb\n",
        "        return z_0"
      ],
      "metadata": {
        "id": "iAm_Y8_1C2Oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module): \n",
        "    def __init__(self, emb_dim:int=384, head:int=3, dropout:float=0.):\n",
        "        \"\"\" \n",
        "        인수:\n",
        "            emb_dim: 임베딩 벡터 길이 \n",
        "            head: 헤드 수\n",
        "            dropout: 드롭 아웃 확률\n",
        "        \"\"\"\n",
        "        super(MultiHeadSelfAttention, self).__init__() \n",
        "        self.head = head\n",
        "        self.emb_dim = emb_dim\n",
        "        self.head_dim = emb_dim // head\n",
        "        self.sqrt_dh = self.head_dim**0.5 # D_h의 제곱근. qk^T를 나누기 위한 계수\n",
        "\n",
        "        # 입력을 q, k, v로 임베딩 하기 위한 선형층 \n",
        "        self.w_q = nn.Linear(emb_dim, emb_dim, bias=False) \n",
        "        self.w_k = nn.Linear(emb_dim, emb_dim, bias=False) \n",
        "        self.w_v = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "\n",
        "        # 드롭 아웃\n",
        "        self.attn_drop = nn.Dropout(dropout)\n",
        "\n",
        "        # MHSA 결과를 출력에 임베딩 하기 위한 선형층\n",
        "        ## 식에는 없지만 드롭 아웃을 사용함 \n",
        "        self.w_o = nn.Sequential(\n",
        "            nn.Linear(emb_dim, emb_dim),\n",
        "            nn.Dropout(dropout) \n",
        "        )\n",
        "\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" \n",
        "        인수:\n",
        "            z: MHSA로의 입력. 사이즈는 (B, N, D)\n",
        "                B: 배치 사이즈, N: 토큰 수, D: 벡터 길이\n",
        "        반환값:\n",
        "            out: MHSA 출력. 사이즈는 (B, N, D)\n",
        "                B: 배치 사이즈, N: 토큰 수, D: 임베딩 벡터 길이\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size, num_patch, _ = z.size()\n",
        "\n",
        "        # 임베딩\n",
        "        ## (B, N, D) -> (B, N, D)\n",
        "        q = self.w_q(z)\n",
        "        k = self.w_k(z)\n",
        "        v = self.w_v(z)\n",
        "\n",
        "        # q, k, v를 헤드로 나눔\n",
        "        ## 먼저 벡터를 헤드 개수(h)로 나눔\n",
        "        ## (B, N, D) -> (B, N, h, D//h)\n",
        "        q = q.view(batch_size, num_patch, self.head, self.head_dim)\n",
        "        k = k.view(batch_size, num_patch, self.head, self.head_dim)\n",
        "        v = v.view(batch_size, num_patch, self.head, self.head_dim)\n",
        "\n",
        "        ## Self-Attention을 계산할 수 있게\n",
        "        ## (배치 사이즈, 헤드, 토큰 수, 패치 벡터) 형태로 변환 \n",
        "        ## (B, N, h, D//h) -> (B, h, N, D//h)\n",
        "        q = q.transpose(1,2)\n",
        "        k = k.transpose(1,2)\n",
        "        v = v.transpose(1,2)\n",
        "\n",
        "        # 내적\n",
        "        ## (B, h, N, D//h) -> (B, h, D//h, N)\n",
        "        k_T = k.transpose(2, 3)\n",
        "        ## (B, h, N, D//h) x (B, h, D//h, N) -> (B, h, N, N) \n",
        "        dots = (q @ k_T) / self.sqrt_dh\n",
        "        ## 열 방향 소프트맥스 함수\n",
        "        attn = F.softmax(dots, dim=-1)\n",
        "        ## 드롭아웃\n",
        "        attn = self.attn_drop(attn)\n",
        "        # 가중합\n",
        "        ## (B, h, N, N) x (B, h, N, D//h) -> (B, h, N, D//h) \n",
        "        out = attn @ v\n",
        "        ## (B, h, N, D//h) -> (B, N, h, D//h)\n",
        "        out = out.transpose(1, 2)\n",
        "        ## (B, N, h, D//h) -> (B, N, D)\n",
        "        out = out.reshape(batch_size, num_patch, self.emb_dim)\n",
        "\n",
        "        # 출력층\n",
        "        ## (B, N, D) -> (B, N, D) \n",
        "        out = self.w_o(out) \n",
        "        return out"
      ],
      "metadata": {
        "id": "Mzkjh1HuFAIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VitEncoderBlock(nn.Module): \n",
        "    def __init__(self, emb_dim:int=384, head:int=4, hidden_dim:int=384*4, dropout:float=0.2):\n",
        "        \"\"\"\n",
        "        인수:\n",
        "            emb_dim: 임베딩 후 벡터 길이\n",
        "            head: 헤드 수\n",
        "            hidden_dim: Encoder Block에서 MLP 중간층의 벡터 길이 \n",
        "                        논문에서와 같이 emb_dim의 4배를 디폴트로 함\n",
        "            dropout: 드롭아웃 확률\n",
        "        \"\"\"\n",
        "        super(VitEncoderBlock, self).__init__()\n",
        "        # 첫번째 Layer Normalization\n",
        "        self.ln1 = nn.LayerNorm(emb_dim)\n",
        "        # MHSA\n",
        "        self.msa = MultiHeadSelfAttention(\n",
        "        emb_dim=emb_dim, head=head,\n",
        "        dropout = dropout,\n",
        "        )\n",
        "        # 두번째 Layer Normalization\n",
        "        self.ln2 = nn.LayerNorm(emb_dim)\n",
        "        # MLP\n",
        "        self.mlp = nn.Sequential( \n",
        "            nn.Linear(emb_dim, hidden_dim), \n",
        "            nn.GELU(),\n",
        "            nn.Dropout(dropout), \n",
        "            nn.Linear(hidden_dim, emb_dim), \n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\" \n",
        "        인수:\n",
        "            z: Encoder Block으로 입력. 사이즈는 (B, N, D)\n",
        "                B: 배치 사이즈, N: 토큰 수, D: 벡터 길이\n",
        "        반환값:\n",
        "            out: Encoder Block의 출력. 사이즈는 (B, N, D)\n",
        "                B: 배치 사이즈, N: 토큰 수, D: 임베딩 벡터 길이 \n",
        "        \"\"\"\n",
        "        # Encoder Block의 전반부 \n",
        "        out = self.msa(self.ln1(z)) + z\n",
        "        # Encoder Block의 후반부 \n",
        "        out = self.mlp(self.ln2(out)) + out \n",
        "        return out"
      ],
      "metadata": {
        "id": "rx14CWY4FY4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Vit(nn.Module): \n",
        "    def __init__(self, in_channels:int=3, num_classes:int=2, emb_dim:int=384, num_patch_row:int=4, image_size:int=224,\n",
        "                 num_blocks:int=4, head:int=4, hidden_dim:int=384*4, dropout:float=0.2):\n",
        "        \"\"\" \n",
        "        인수:\n",
        "            in_channels: 입력 이미지의 채널 수\n",
        "            num_classes: 이미지 분류 클래스 수\n",
        "            emb_dim: 임베딩 후 벡터 길이\n",
        "            num_patch_row: 한 변의 패치 수\n",
        "            image_size: 입력 이미지의 한 변의 길이. 입력 이미지의 높이, 폭은 같은 길이를 가정 \n",
        "            num_blocks: Encoder Block 수\n",
        "            head: 헤드 수\n",
        "            hidden_dim: Encoder Block의 MLP 중간층의 벡터 길이 \n",
        "            dropout: 드롭아웃 확률\n",
        "        \"\"\"\n",
        "        super(Vit, self).__init__()\n",
        "        # Input Layer \n",
        "        self.input_layer = VitInputLayer(\n",
        "            in_channels, \n",
        "            emb_dim, \n",
        "            num_patch_row, \n",
        "            image_size)\n",
        "\n",
        "        # Encoder. Encoder Block 여러 층 \n",
        "        self.encoder = nn.Sequential(*[\n",
        "            VitEncoderBlock(\n",
        "                emb_dim=emb_dim,\n",
        "                head=head,\n",
        "                hidden_dim=hidden_dim,\n",
        "                dropout = dropout\n",
        "            )\n",
        "            for _ in range(num_blocks)])\n",
        "\n",
        "        # MLP Head\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(emb_dim),\n",
        "            nn.Linear(emb_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        인수:\n",
        "            x: ViT로 입력되는 이미지. 사이즈는 (B, C, H, W)\n",
        "                B: 배치 사이즈, C: 채널 수, H: 높이, W: 폭\n",
        "        반환값:\n",
        "            out: ViT의 출력. 사이즈는 (B, M)\n",
        "                B: 배치 사이즈, M: 클래스 수 \n",
        "        \"\"\"\n",
        "        # Input Layer\n",
        "        ## (B, C, H, W) -> (B, N, D)\n",
        "        ## N: 토큰 수(=배치 수+1), D: 벡터 길이 \n",
        "        out = self.input_layer(x)\n",
        "        \n",
        "        # Encoder\n",
        "        ## (B, N, D) -> (B, N, D)\n",
        "        out = self.encoder(out)\n",
        "\n",
        "        # 클래스 토큰만 꺼냄\n",
        "        ## (B, N, D) -> (B, D)\n",
        "        cls_token = out[:,0]\n",
        "\n",
        "        # MLP Head\n",
        "        ## (B, D) -> (B, M)\n",
        "        pred = self.mlp_head(cls_token)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "GUgeNljGFc89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 마지막 노드의 출력을 2로 고정\n",
        "num_classes = 2\n",
        "channel = 3\n",
        "vit = Vit(in_channels=channel, num_classes=num_classes)\n",
        "\n",
        "# 모델 개요 표시\n",
        "summary(vit,(5, 3, 224, 224))"
      ],
      "metadata": {
        "id": "o_28nNtEFiDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5015a15-8c0b-408e-ecc6-b436b9e8dbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "Vit                                           [5, 2]                    --\n",
              "├─VitInputLayer: 1-1                          [5, 17, 384]              6,912\n",
              "│    └─Conv2d: 2-1                            [5, 384, 4, 4]            3,613,056\n",
              "├─Sequential: 1-2                             [5, 17, 384]              --\n",
              "│    └─VitEncoderBlock: 2-2                   [5, 17, 384]              --\n",
              "│    │    └─LayerNorm: 3-1                    [5, 17, 384]              768\n",
              "│    │    └─MultiHeadSelfAttention: 3-2       [5, 17, 384]              590,208\n",
              "│    │    └─LayerNorm: 3-3                    [5, 17, 384]              768\n",
              "│    │    └─Sequential: 3-4                   [5, 17, 384]              1,181,568\n",
              "│    └─VitEncoderBlock: 2-3                   [5, 17, 384]              --\n",
              "│    │    └─LayerNorm: 3-5                    [5, 17, 384]              768\n",
              "│    │    └─MultiHeadSelfAttention: 3-6       [5, 17, 384]              590,208\n",
              "│    │    └─LayerNorm: 3-7                    [5, 17, 384]              768\n",
              "│    │    └─Sequential: 3-8                   [5, 17, 384]              1,181,568\n",
              "│    └─VitEncoderBlock: 2-4                   [5, 17, 384]              --\n",
              "│    │    └─LayerNorm: 3-9                    [5, 17, 384]              768\n",
              "│    │    └─MultiHeadSelfAttention: 3-10      [5, 17, 384]              590,208\n",
              "│    │    └─LayerNorm: 3-11                   [5, 17, 384]              768\n",
              "│    │    └─Sequential: 3-12                  [5, 17, 384]              1,181,568\n",
              "│    └─VitEncoderBlock: 2-5                   [5, 17, 384]              --\n",
              "│    │    └─LayerNorm: 3-13                   [5, 17, 384]              768\n",
              "│    │    └─MultiHeadSelfAttention: 3-14      [5, 17, 384]              590,208\n",
              "│    │    └─LayerNorm: 3-15                   [5, 17, 384]              768\n",
              "│    │    └─Sequential: 3-16                  [5, 17, 384]              1,181,568\n",
              "├─Sequential: 1-3                             [5, 2]                    --\n",
              "│    └─LayerNorm: 2-6                         [5, 384]                  768\n",
              "│    └─Linear: 2-7                            [5, 2]                    770\n",
              "===============================================================================================\n",
              "Total params: 10,714,754\n",
              "Trainable params: 10,714,754\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 324.52\n",
              "===============================================================================================\n",
              "Input size (MB): 3.01\n",
              "Forward/backward pass size (MB): 11.75\n",
              "Params size (MB): 42.83\n",
              "Estimated Total Size (MB): 57.59\n",
              "==============================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load('./pythonlibs/pretrained_vit/model.pt', map_location='cpu')\n",
        "vit.load_state_dict(checkpoint['net'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGpGUG0SgLn-",
        "outputId": "c70260a9-692a-40b5-979d-b4260652df03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder block 단위로 Attention weight를 확보\n",
        "\n",
        "attention_weight = []\n",
        "\n",
        "# 이미지 리사이즈, centorcrop 등\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "invTrans = transforms.Compose([\n",
        "    transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255], std=[1/0.229, 1/0.224, 1/0.255]),])"
      ],
      "metadata": {
        "id": "vIpYI07HgLx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Attention map을 시각화 하고싶은 이미지 파일 준비\n",
        "\n",
        "image = Image.open(os.path.join(test_dir, 'colon', 'colonca10.jpeg'))\n",
        "x = transform(image)\n",
        "x = x.view(1, *x.shape)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_AjYqSjgL28",
        "outputId": "c6d04d77-f380-433c-c551-dc3ccc1bfda6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kL2CsQGSkLfj",
        "outputId": "f4b3d10f-d4df-47bb-cf8b-8b97e48303f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vit(\n",
            "  (input_layer): VitInputLayer(\n",
            "    (patch_emb_layer): Conv2d(3, 384, kernel_size=(56, 56), stride=(56, 56))\n",
            "  )\n",
            "  (encoder): Sequential(\n",
            "    (0): VitEncoderBlock(\n",
            "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (msa): MultiHeadSelfAttention(\n",
            "        (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
            "        (w_o): Sequential(\n",
            "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (1): GELU(approximate=none)\n",
            "        (2): Dropout(p=0.2, inplace=False)\n",
            "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (4): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (1): VitEncoderBlock(\n",
            "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (msa): MultiHeadSelfAttention(\n",
            "        (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
            "        (w_o): Sequential(\n",
            "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (1): GELU(approximate=none)\n",
            "        (2): Dropout(p=0.2, inplace=False)\n",
            "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (4): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (2): VitEncoderBlock(\n",
            "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (msa): MultiHeadSelfAttention(\n",
            "        (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
            "        (w_o): Sequential(\n",
            "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (1): GELU(approximate=none)\n",
            "        (2): Dropout(p=0.2, inplace=False)\n",
            "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (4): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (3): VitEncoderBlock(\n",
            "      (ln1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (msa): MultiHeadSelfAttention(\n",
            "        (w_q): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_k): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (w_v): Linear(in_features=384, out_features=384, bias=False)\n",
            "        (attn_drop): Dropout(p=0.2, inplace=False)\n",
            "        (w_o): Sequential(\n",
            "          (0): Linear(in_features=384, out_features=384, bias=True)\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): Sequential(\n",
            "        (0): Linear(in_features=384, out_features=1536, bias=True)\n",
            "        (1): GELU(approximate=none)\n",
            "        (2): Dropout(p=0.2, inplace=False)\n",
            "        (3): Linear(in_features=1536, out_features=384, bias=True)\n",
            "        (4): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (mlp_head): Sequential(\n",
            "    (0): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
            "    (1): Linear(in_features=384, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(vit.encoder)):\n",
        "    target_module = vit.encoder[i].msa.attn_drop\n",
        "    features = extract(vit, target_module, x.to('cuda:0')) # shape: (1, H, N, N)\n",
        "    attention_weight.append([features.to('cpu').detach().numpy().copy()])\n",
        "\n",
        "attention_weight = np.squeeze(np.concatenate(attention_weight), axis=1) # shape: (L, H, N, N)\n",
        "print(attention_weight.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aatoF0Q-gL5z",
        "outputId": "0822fa73-89a3-4d8b-b7ca-0c8e92af52b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4, 17, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 헤드 방향으로 평균 계산\n",
        "mean_head = np.mean(attention_weight, axis=1) # shape: (L, N, N)\n",
        "# NxN 단위 행렬 합산\n",
        "mean_head = mean_head + np.eye(mean_head.shape[1])\n",
        "# 정규화\n",
        "mean_head = mean_head / mean_head.sum(axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "v = mean_head[-1]\n",
        "for n in range(1, len(mean_head)):\n",
        "    v = np.matmul(v, mean_head[-1 - n])\n",
        "\n",
        "# CLS토큰과 각 패치토큰 사이의 Attention Weight로부터\n",
        "# 입력 이미지 사이즈까지 정규화 하면서 리사이즈한 Attention Map을 생성\n",
        "mask = v[0, 1:].reshape(4, 4)\n",
        "attention_map = cv2.resize(mask / mask.max(), (x.shape[2], x.shape[3]))[..., np.newaxis]\n",
        "\n",
        "# 입력 이미지를 정규화 전으로 되돌림\n",
        "inv_tensor = invTrans(x)[0]\n",
        "# Attention Map과 Attention을 입힌 이미지를 생성\n",
        "mask = torch.from_numpy(attention_map.astype(np.float32))\n",
        "_, result = visualize_cam(mask, inv_tensor.to(device))\n",
        "\n",
        "# 입력 이미지, Attention Map, Attention을 입힌 이미지를 시각화 \n",
        "plt.figure(figsize=[20, 20])\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title('input')\n",
        "plt.xticks(color=\"None\")\n",
        "plt.yticks(color=\"None\")\n",
        "plt.tick_params(length=0)\n",
        "plt.imshow(inv_tensor.permute(1,2,0), vmin=0, vmax=1)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title('attention')\n",
        "plt.xticks(color=\"None\")\n",
        "plt.yticks(color=\"None\")\n",
        "plt.tick_params(length=0)\n",
        "plt.imshow(attention_map.reshape(224,-1), cmap='jet')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title('plot')\n",
        "plt.xticks(color=\"None\")\n",
        "plt.yticks(color=\"None\")\n",
        "plt.tick_params(length=0)\n",
        "plt.imshow(result.detach().cpu().numpy().transpose(1,2,0))\n",
        "plt.savefig('./attention_rollout.pdf')\n",
        "plt.clf()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "RpuEjOEdgL78",
        "outputId": "1888b092-757a-44b3-f335-ccf430c9e74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x1440 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}